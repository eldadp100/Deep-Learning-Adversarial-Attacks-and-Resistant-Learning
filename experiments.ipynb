{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments:\n",
    "The experiments are done on Traffic Signs classification case study. Signs classification is a component of autonomous\n",
    "vehicles and therefore its resistance to adversarial attacks is highly crucial. We talk about that much more in the\n",
    "project report.\n",
    "\n",
    "The dataset is GTSRB (German Traffic Sign Recognition).\n",
    "I downloaded the dataset from: https://github.com/tomlawrenceuk/GTSRB-Dataloader\n",
    "\n",
    "In short the experiments are:\n",
    "1) Apply PGD and FGSM attacks on a spatial convolutional neural network.\n",
    "2) Comparing robustness of adversarial training using FGSM versus using PGD.\n",
    "3) Universality of PGD attack - we show that using PGD adversarial training we cover any first order attack (we show\n",
    "   resistance to some known adversarial attacks - not a theoretical proof)\n",
    "4) Capacity and Adversarial Robustness (see more details in Experiment 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries:\n",
    "\n",
    "import torch\n",
    "import attacks\n",
    "import configs\n",
    "import datasets\n",
    "import dls\n",
    "import helper\n",
    "import models\n",
    "import trainer\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialization:\n",
    "    - export configs\n",
    "    - validate paths\n",
    "    - set random seed\n",
    "    - configure device (GPU / CPU)\n",
    "    - load datasets\n",
    "    - create hyperparameters generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configs\n",
    "experiment_configs = configs.TrafficSigns_experiments_configs\n",
    "experiment_hps_sets = configs.TrafficSigns_experiments_hps\n",
    "show_test_successful_attacks_plots = configs.show_test_successful_attacks_plots\n",
    "save_test_successful_attacks_plots = configs.show_test_successful_attacks_plots\n",
    "\n",
    "# paths existence validation and initialization\n",
    "assert os.path.exists(configs.data_root_dir), \"The dataset should be in ./data/GTSRB\"\n",
    "assert os.path.exists(os.path.join(configs.data_root_dir, \"GTSRB\")), \"The dataset should be in ./data/GTSRB\"\n",
    "if not os.path.exists(configs.results_folder):\n",
    "    os.mkdir(configs.results_folder)\n",
    "if os.path.exists(configs.plots_folder):\n",
    "    shutil.rmtree(configs.plots_folder)\n",
    "    os.mkdir(configs.plots_folder)\n",
    "if os.path.exists(configs.logger_path):\n",
    "    os.remove(configs.logger_path)\n",
    "\n",
    "# seed\n",
    "if configs.seed is not None:\n",
    "    # np.random.seed(configs.seed)\n",
    "    torch.manual_seed(configs.seed)\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# get datasets\n",
    "transform = experiment_configs[\"data_transform\"]\n",
    "_training_dataset = datasets.GTSRB(root_dir=configs.data_root_dir, train=True, transform=transform)\n",
    "_testing_dataset = datasets.GTSRB(root_dir=configs.data_root_dir, train=False, transform=transform)\n",
    "\n",
    "# create hyperparameters generators\n",
    "net_training_hps_gen = helper.GridSearch(experiment_hps_sets[\"nets_training\"])\n",
    "fgsm_attack_hps_gen = helper.GridSearch(experiment_hps_sets[\"FGSM\"])\n",
    "pgd_attack_hps_gen = helper.GridSearch(experiment_hps_sets[\"PGD\"])\n",
    "\n",
    "# loss and general training componenets:\n",
    "_loss_fn = experiment_configs[\"loss_function\"]\n",
    "stop_criteria = experiment_configs[\"stopping_criteria\"]\n",
    "epochs = trainer.Epochs(stop_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1: PGD and FGSM attacks in practice.\n",
    "\n",
    "In this experiment we will attack a network using PGD and FGSM attacks.\n",
    "The experiment illustrates that PGD and FGSM attacks actually works on GTSRB dataset.\n",
    "We train and attack a Spatial Transformer Network which is invariant to geometrical\n",
    "transformations (rotations and scaling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-980f9544a986>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     67\u001B[0m }\n\u001B[0;32m     68\u001B[0m \u001B[0mmnist_net\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_conv_nn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmnist_net_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m \u001B[0mexp_1_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexperiment_1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmnist_net\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_loss_fn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_train_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_test_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnetwork_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"MNIST experiment_1\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot_successful_attacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-980f9544a986>\u001B[0m in \u001B[0;36mexperiment_1\u001B[1;34m(net, loss_fn, train_dataset, test_dataset, network_name, plot_successful_attacks)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mexperiment_hps_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfigs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMINIST_experiments_hps\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m     \u001B[0mnet_train_hps_gen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGridSearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexperiment_hps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"nets_training\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m     \u001B[0mpgd_attack_hps_gen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGridSearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexperiment_hps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"PGD\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0mfgsm_attack_hps_gen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGridSearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexperiment_hps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"PGD\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\GIT\\CNN_course_final_project\\src\\helper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, hps_dict)\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhps_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhps_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_keys\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhps_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_keys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_keys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": [
    "def experiment_1_func(net, _loss_fn, _training_dataset, _testing_dataset, epochs,\n",
    "                      net_name=\"\", train_attack=None, load_checkpoint=False, save_checkpoint=True):\n",
    "    if load_checkpoint:\n",
    "        checkpoint_path = os.path.join(configs.checkpoints_folder, \"{}.pt\".format(net_name))\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        net.load_state_dict(checkpoint[\"trained_net\"])\n",
    "        net_hp = checkpoint[\"net_hp\"]\n",
    "        fgsm_hp = checkpoint[\"fgsm_hp\"]\n",
    "        pgd_hp = checkpoint[\"pgd_hp\"]\n",
    "        resistance_results = checkpoint[\"resistance_results\"]\n",
    "\n",
    "    else:\n",
    "        # apply hyperparameters-search to get trained network\n",
    "        net, net_hp, net_acc = helper.full_train_of_nn_with_hps(net, _loss_fn, _training_dataset,\n",
    "                                                                net_training_hps_gen,\n",
    "                                                                epochs, device=device, train_attack=train_attack)\n",
    "        net.eval()\n",
    "\n",
    "        # attack net (trained) using FGSM:\n",
    "        _, fgsm_hp, fgsm_score = helper.full_attack_of_trained_nn_with_hps(net, _loss_fn, _training_dataset,\n",
    "                                                                           fgsm_attack_hps_gen, net_hp,\n",
    "                                                                           attacks.FGSM,\n",
    "                                                                           device=device,\n",
    "                                                                           plot_successful_attacks=False)\n",
    "\n",
    "        # attack net (trained) using PGD:\n",
    "        _, pgd_hp, pgd_score = helper.full_attack_of_trained_nn_with_hps(net, _loss_fn, _training_dataset,\n",
    "                                                                         pgd_attack_hps_gen, net_hp, attacks.PGD,\n",
    "                                                                         device=device,\n",
    "                                                                         plot_successful_attacks=False)\n",
    "\n",
    "        # measure attacks on test (holdout)\n",
    "        resistance_results = helper.measure_resistance_on_test(net, _loss_fn, _testing_dataset,\n",
    "                                                               [(attacks.FGSM, fgsm_hp),\n",
    "                                                                (attacks.PGD, pgd_hp)],\n",
    "                                                               plot_successful_attacks=show_test_successful_attacks_plots,\n",
    "                                                               device=device)\n",
    "\n",
    "    test_acc = resistance_results[\"test_acc\"]  # the accuracy without applying any attack\n",
    "    fgsm_res = resistance_results[\"%fgsm\"]\n",
    "    pgd_res = resistance_results[\"%pgd\"]\n",
    "\n",
    "    # print scores:\n",
    "    print(\"TEST SCORES of {}:\".format(net_name))\n",
    "    print(\"accuracy on test:            {}\".format(test_acc))\n",
    "    print(\"%FGSM successful attacks:    {}\".format(fgsm_res))\n",
    "    print(\"%PGD successful attacks:     {}\\n\".format(pgd_res))\n",
    "\n",
    "    # save checkpoint\n",
    "    res_dict = {\n",
    "        \"trained_net\": net,\n",
    "        \"net_hp\": net_hp,\n",
    "        \"fgsm_hp\": fgsm_hp,\n",
    "        \"pgd_hp\": pgd_hp,\n",
    "        \"resistance_results\": resistance_results\n",
    "    }\n",
    "\n",
    "    if save_checkpoint:\n",
    "        to_save_res_dict = res_dict\n",
    "        to_save_res_dict[\"trained_net\"] = net.state_dict()\n",
    "        checkpoint_path = os.path.join(configs.checkpoints_folder, \"{}.pt\".format(net_name))\n",
    "        torch.save(to_save_res_dict, checkpoint_path)\n",
    "\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "# define network\n",
    "net_arch = models.TrafficSignNet().to(device)\n",
    "# apply experiment 1\n",
    "exp1_res_dict = experiment_1_func(net_arch, _loss_fn, _training_dataset, _testing_dataset, epochs,\n",
    "                                      net_name=\"Spatial Transformer Network(STN)\")\n",
    "# save results\n",
    "original_trained_net = exp1_res_dict[\"trained_net\"]\n",
    "net_hp = exp1_res_dict[\"net_hp\"]\n",
    "fgsm_hp = exp1_res_dict[\"fgsm_hp\"]\n",
    "pgd_hp = exp1_res_dict[\"pgd_hp\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Comparing defensing using FGSM versus using PGD\n",
    "In this experiment we will build 2 robust networks to the same task as the paper suggest but one will be resistant to FGSM attack\n",
    "and the second to PGD attack.\n",
    "\n",
    "Then we will examine the following results of the paper:\n",
    "\n",
    "1. We show that network 1 (i.e. trained to be resistant to FGSM attack) is resistant to FGSM but not to PGD. Therefore we get that:\n",
    " - Resistancy FGSM attack does not implies PGD resistency.\n",
    " - FGSM attack is not universal.\n",
    "2. We show that network 2 (i.e. trained to be resistant to PGD attack) is resistant to both PGD and FGSM.\n",
    "\n",
    "   In the next experiment we show that network 2 is resistant to some other attacks and this examine the universality of PGD (i.e. that resistancy to\n",
    "   PGD implies resistancy to any other first order attack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# epochs = trainer.Epochs(trainer.ConstantStopping(25))\n",
    "epochs.restart()\n",
    "fgsm_robust_net = models.TrafficSignNet().to(device)\n",
    "fgsm_attack = attacks.FGSM(fgsm_robust_net, _loss_fn, fgsm_hp)\n",
    "experiment_1_func(fgsm_robust_net, _loss_fn, _training_dataset, _testing_dataset, epochs,\n",
    "                  net_name=\"robust net built using FGSM\", train_attack=fgsm_attack)\n",
    "\n",
    "epochs.restart()\n",
    "pgd_robust_net = models.TrafficSignNet().to(device)\n",
    "pgd_attack = attacks.PGD(pgd_robust_net, _loss_fn, pgd_hp)\n",
    "experiment_1_func(pgd_robust_net, _loss_fn, _training_dataset, _testing_dataset, epochs,\n",
    "                      net_name=\"robust net built using PGD\", train_attack=pgd_attack)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Universality of PGD attack\n",
    "In this experiment we will attack the network that is trained to be resistant to PGD attack with different attacks\n",
    "with different parameters and show that it is also resistant to those attacks.\n",
    "\n",
    "Note that we already saw in experiment 2 that this network is resistant to FGSM attack with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attacks_lst = [\n",
    "    (attacks.FGSM, {\"epsilon\": 0.001}),\n",
    "    (attacks.FGSM, {\"epsilon\": 0.005}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.4, \"steps\": 60, \"alpha\": 0.001}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.2, \"steps\": 20, \"alpha\": 0.005}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.3, \"steps\": 40, \"alpha\": 0.005}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.2, \"steps\": 40, \"alpha\": 0.01}),\n",
    "    (attacks.MomentumFGSM, {\"epsilon\": 0.2, \"steps\": 40, \"alpha\": 0.01, \"momentum\":0.9}),\n",
    "    (attacks.MomentumFGSM, {\"epsilon\": 0.4, \"steps\": 30, \"alpha\": 0.001, \"momentum\":0.95}),\n",
    "]\n",
    "pgd_resistance_results = helper.measure_resistance_on_test(pgd_robust_net, _loss_fn, _testing_dataset, attacks_lst,\n",
    "                                                           plots_title=\"robust net built using PGD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Capacity and Adversarial Robustness\n",
    "In this experiment we will examine the following statements:\n",
    "\n",
    "1. Capacity alone helps: High capacity models are more robust to adversarial attacks then low capacity models.\n",
    "2. Weak models may fail to learn non-trivial classifiers: We show that we can't build (using the paper method) a robust model\n",
    "   when the model is with low capacity. Specifically we will show that after training with the paper method to build a robust\n",
    "   model we get an extremely underfitted model.\n",
    "3. The value of the saddle point problem decreases as we increase the capacity\n",
    "4. More capacity and stronger adversaries decrease transferability: we take transferred adversarial inputs and show that their\n",
    "   gradients correlation with the source becomes less significant. More details on that experiment can be found in the project file.\n",
    "\n",
    "\n",
    "\n",
    "Technical Details:\n",
    "To create the increased capacity networks we use create_conv_nn from models.py. A description on the parameters is in\n",
    "ConvNN class. In short, channels_lst specifies the number of channels at each layer and extras_blocks_components\n",
    "specifies the components on each block of the network (e.g. dropout, maxpool). #FC_Layers is the number of layers that\n",
    "follows the convolutional layers. There are limitations on some of the parameters - 2 <= len(channels_lst) <= 5\n",
    "and #FC_Layers > 0. CNN_out_channels for applying 1x1 conv layer with CNN_out_channels output channels - None for\n",
    "ignoring this feature. in_wh is width and height of the pictures. out_size is the number of classes. For more details\n",
    "see ConvNN class description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inc_capacity_nets = []\n",
    "base_net_params = {\n",
    "    \"channels_lst\": [3, 20, 40],  # the first element is number of input channels\n",
    "    \"extras_blocks_components\": [],  # [\"dropout\"],\n",
    "    # \"p_dropout\": 0.1,\n",
    "    \"activation\": torch.nn.LeakyReLU,\n",
    "    \"out_size\": 43,\n",
    "    \"in_wh\": 32,\n",
    "    \"#FC_Layers\": 2,\n",
    "    \"CNN_out_channels\": 30  # apply 1x1 conv layer to achieve that - to control mem. None to not use.\n",
    "}\n",
    "for i in range(1, 9):\n",
    "    base_net_params[\"channels_lst\"] = [3, 10 * i, 20 * i]\n",
    "    base_net_params[\"#FC_Layers\"] = 1 + i // 2\n",
    "    base_net_params[\"CNN_out_channels\"] = i * 5\n",
    "    cap_net = models.create_conv_nn(base_net_params)\n",
    "    inc_capacity_nets.append(cap_net)\n",
    "for i, net in enumerate(inc_capacity_nets):\n",
    "    net = net.to(device)\n",
    "    epochs.restart()\n",
    "    experiment_1_func(net, _loss_fn, _training_dataset, _testing_dataset, epochs,\n",
    "                        net_name=\"capacity_{}\".format(i))\n",
    "\n",
    "# visualize and stufff........"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}