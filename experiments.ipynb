{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments:\n",
    "The experiments are done on Traffic Signs classification case study. Signs classification is a component of autonomous\n",
    "vehicles and therefore its resistance to adversarial attacks is highly crucial. We talk about that much more in the\n",
    "project report.\n",
    "\n",
    "The dataset is GTSRB (German Traffic Sign Recognition).\n",
    "I downloaded the dataset from: https://github.com/tomlawrenceuk/GTSRB-Dataloader\n",
    "\n",
    "In short the experiments are:\n",
    "1) Apply PGD and FGSM attacks on a spatial convolutional neural network.\n",
    "2) Comparing robustness of adversarial training using FGSM versus using PGD.\n",
    "3) Universality of PGD attack - we show that using PGD adversarial training we cover any first order attack (we show\n",
    "   resistance to some known adversarial attacks - not a theoretical proof)\n",
    "4) Capacity and Adversarial Robustness (see more details in Experiment 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries:\n",
    "\n",
    "import torch\n",
    "import attacks\n",
    "import configs\n",
    "import datasets\n",
    "import dls\n",
    "import helper\n",
    "import models\n",
    "import trainer\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialization:\n",
    "    - export configs\n",
    "    - validate paths\n",
    "    - set random seed\n",
    "    - configure device (GPU / CPU)\n",
    "    - load datasets\n",
    "    - create hyperparameters generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configs\n",
    "experiment_configs = configs.TrafficSigns_experiments_configs\n",
    "experiment_hps_sets = configs.TrafficSigns_experiments_hps\n",
    "show_test_successful_attacks_plots = configs.show_test_successful_attacks_plots\n",
    "save_test_successful_attacks_plots = configs.show_test_successful_attacks_plots\n",
    "\n",
    "# paths existence validation and initialization\n",
    "assert os.path.exists(configs.data_root_dir), \"The dataset should be in ./data/GTSRB\"\n",
    "assert os.path.exists(os.path.join(configs.data_root_dir, \"GTSRB\")), \"The dataset should be in ./data/GTSRB\"\n",
    "if not os.path.exists(configs.results_folder):\n",
    "    os.mkdir(configs.results_folder)\n",
    "if os.path.exists(configs.plots_folder):\n",
    "    shutil.rmtree(configs.plots_folder)\n",
    "    os.mkdir(configs.plots_folder)\n",
    "if os.path.exists(configs.logger_path):\n",
    "    os.remove(configs.logger_path)\n",
    "\n",
    "# seed\n",
    "if configs.seed is not None:\n",
    "    # np.random.seed(configs.seed)\n",
    "    torch.manual_seed(configs.seed)\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# get datasets\n",
    "transform = experiment_configs[\"data_transform\"]\n",
    "_training_dataset = datasets.GTSRB(root_dir=configs.data_root_dir, train=True, transform=transform)\n",
    "_testing_dataset = datasets.GTSRB(root_dir=configs.data_root_dir, train=False, transform=transform)\n",
    "\n",
    "# create hyperparameters generators\n",
    "net_training_hps_gen = helper.GridSearch(experiment_hps_sets[\"nets_training\"])\n",
    "fgsm_attack_hps_gen = helper.GridSearch(experiment_hps_sets[\"FGSM\"])\n",
    "pgd_attack_hps_gen = helper.GridSearch(experiment_hps_sets[\"PGD\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1: PGD and FGSM attacks in practice.\n",
    "\n",
    "In this experiment we will attack a network using PGD and FGSM attacks.\n",
    "The experiment illustrates that PGD and FGSM attacks actually works also on GTSRB dataset.\n",
    "We train and attack a Spatial Transformer Network which is invariant to geometrical\n",
    "transformations (rotations and scaling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-980f9544a986>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     67\u001B[0m }\n\u001B[0;32m     68\u001B[0m \u001B[0mmnist_net\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_conv_nn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmnist_net_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m \u001B[0mexp_1_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexperiment_1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmnist_net\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_loss_fn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_train_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_test_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnetwork_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"MNIST experiment_1\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot_successful_attacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-980f9544a986>\u001B[0m in \u001B[0;36mexperiment_1\u001B[1;34m(net, loss_fn, train_dataset, test_dataset, network_name, plot_successful_attacks)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mexperiment_hps_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfigs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMINIST_experiments_hps\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m     \u001B[0mnet_train_hps_gen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGridSearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexperiment_hps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"nets_training\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m     \u001B[0mpgd_attack_hps_gen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGridSearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexperiment_hps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"PGD\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0mfgsm_attack_hps_gen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGridSearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexperiment_hps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"PGD\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\GIT\\CNN_course_final_project\\src\\helper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, hps_dict)\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhps_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhps_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_keys\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhps_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhps_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_keys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps_keys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Comparing defensing using FGSM versus using PGD\n",
    "In this experiment we will build 2 robust networks to the same task as the paper suggest but one will be resistant to FGSM attack\n",
    "and the second to PGD attack.\n",
    "\n",
    "Then we will examine the following results of the paper:\n",
    "\n",
    "1. We show that network 1 (i.e. trained to be resistant to FGSM attack) is resistant to FGSM but not to PGD. Therefore we get that:\n",
    " - Resistancy FGSM attack does not implies PGD resistency.\n",
    " - FGSM attack is not universal.\n",
    "2. We show that network 2 (i.e. trained to be resistant to PGD attack) is resistant to both PGD and FGSM.\n",
    "\n",
    "   In the next experiment we show that network 2 is resistant to some other attacks and this examine the universality of PGD (i.e. that resistancy to\n",
    "   PGD implies resistancy to any other first order attack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Universality of PGD attack\n",
    "In this experiment we will attack the network that is trained to be resistant to PGD attack\n",
    "with other attacks like: ...........\n",
    "\n",
    "\n",
    "Note that we already saw in experiment 2 that this network is resistant to FGSM attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attacks_lst = [attacks.FGSM, attacks.PGD] # TODO: add more attacks\n",
    "pgd_resistance_results = helper.measure_resistance_on_test(pgd_resistant_mnist_net, _loss_fn, _test_dataset, attacks_lst plots_title=\"robust net built using PGD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Capacity and Adversarial Robustness\n",
    "In this experiment we will examine the following statements:\n",
    "\n",
    "1. Capacity alone helps: High capacity models are more robust to adversarial attacks then low capacity models.\n",
    "2. Weak models may fail to learn non-trivial classifiers: We show that we can't build (using the paper method) a robust model\n",
    "   when the model is with low capacity. Specifically we will show that after training with the paper method to build a robust\n",
    "   model we get an extremely underfitted model.\n",
    "3. The value of the saddle point problem decreases as we increase the capacity\n",
    "4. More capacity and stronger adversaries decrease transferability: we take transferred adversarial inputs and show that their\n",
    "   gradients correlation with the source becomes less significant. More details on that experiment can be found in the project file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# visualize and stufff........"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}