{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Experiments:\n",
    "This file is a \"proof of concept\" to my system. We show that the experiments yields the same results as in the paper.\n",
    "\n",
    "The experiments are the same as in GTSRB, In short are:\n",
    "\n",
    "1. Apply PGD and FGSM attacks on a convolutional neural network.\n",
    "\n",
    "2. Comparing robustness of adversarial training using FGSM versus using PGD.\n",
    "\n",
    "3. Applying experiments 1+2 on a spatial convolutional neural network.\n",
    "\n",
    "4. Testing the relation of capacity and adversarial robustness.\n",
    "\n",
    "Almost all of the code is the same. I didn't make a general experiment for readability of GTSRB which is\n",
    "more important component of the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries:\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import attacks\n",
    "import configs\n",
    "from torchvision.datasets import MNIST\n",
    "import helper\n",
    "import models\n",
    "import trainer\n",
    "import os\n",
    "import shutil\n",
    "import logger\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initializations\n",
    "    - initialize a logger\n",
    "    - set random seed\n",
    "    - set device\n",
    "    - export experiment configs\n",
    "    - validate paths\n",
    "    - load datasets\n",
    "    - create hyperparameters generators\n",
    "    \n",
    "*Note - jupyter doesn't clean fds as normal python execution does. If there is the error of \"logger is used by another process\" then terminate and start again the jupyter kernel from terminal (i.e. conrol+c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment_configs = configs.MNIST_experiments_configs\n",
    "experiment_hps_sets = configs.MNIST_experiments_hps\n",
    "experiment_results_folder = os.path.join(configs.results_folder, \"MNIST\")\n",
    "experiment_checkpoints_folder = os.path.join(configs.checkpoints_folder, \"MNIST\")\n",
    "plots_folder = os.path.join(experiment_results_folder, \"plots\")\n",
    "logger_path = os.path.join(experiment_results_folder, \"log.txt\")\n",
    "\n",
    "# paths existence validation and initialization\n",
    "if not os.path.exists(configs.results_folder):\n",
    "    os.mkdir(configs.results_folder)\n",
    "if not os.path.exists(experiment_results_folder):\n",
    "    os.mkdir(experiment_results_folder)\n",
    "if not os.path.exists(configs.checkpoints_folder):\n",
    "    os.mkdir(experiment_results_folder)\n",
    "if not os.path.exists(experiment_checkpoints_folder):\n",
    "    os.mkdir(experiment_checkpoints_folder)\n",
    "if os.path.exists(plots_folder):\n",
    "    shutil.rmtree(plots_folder)\n",
    "    time.sleep(.0001)\n",
    "os.mkdir(plots_folder)\n",
    "if os.path.exists(logger_path):\n",
    "    os.remove(logger_path)\n",
    "\n",
    "# set logger\n",
    "logger.init_log(logger_path)\n",
    "logger.log_print(\"checkpoints folder: {}\".format(experiment_checkpoints_folder))\n",
    "logger.log_print(\"save checkpoints: {}\".format(configs.save_checkpoints))\n",
    "logger.log_print(\"load checkpoints: {}\".format(configs.load_checkpoints))\n",
    "logger.log_print(\"results folder: {}\".format(experiment_results_folder))\n",
    "logger.log_print(\"show results:  {}\".format(configs.show_attacks_plots))\n",
    "logger.log_print(\"save results:  {}\".format(configs.save_attacks_plots))\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.log_print(\"execution device: {}\".format(device))\n",
    "\n",
    "# seed\n",
    "if configs.seed is not None:\n",
    "    torch.manual_seed(configs.seed)\n",
    "    logger.log_print(\"seed: {}\".format(configs.seed))\n",
    "\n",
    "# get datasets\n",
    "path_to_save_data = os.path.join(\".\", \"datasets\", \"mnist_data\")\n",
    "_training_dataset = MNIST(path_to_save_data, train=True, download=True,\n",
    "                          transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
    "_testing_dataset = MNIST(path_to_save_data, train=False, download=True,\n",
    "                         transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
    "# create hyperparameters generators\n",
    "net_training_hps_gen = helper.GridSearch(experiment_hps_sets[\"nets_training\"])\n",
    "fgsm_attack_hps_gen = helper.GridSearch(experiment_hps_sets[\"FGSM\"])\n",
    "pgd_attack_hps_gen = helper.GridSearch(experiment_hps_sets[\"PGD\"])\n",
    "\n",
    "# loss and general training componenets:\n",
    "_loss_fn = experiment_configs[\"loss_function\"]\n",
    "training_stop_criteria = experiment_configs[\"training_stopping_criteria\"]\n",
    "adv_training_stop_criteria = experiment_configs[\"adversarial_training_stopping_criteria\"]\n",
    "epochs = trainer.Epochs(training_stop_criteria)  # epochs obj for not adversarial training\n",
    "adv_epochs = trainer.Epochs(adv_training_stop_criteria)  # epochs obj for adversarial training\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1: PGD and FGSM attacks in practice.\n",
    "\n",
    "In this experiment we will attack a network using PGD and FGSM attacks.\n",
    "The experiment illustrates that PGD and FGSM attacks works on MNIST dataset.\n",
    "We train and attack a Spatial Transformer Network which is invariant to geometrical\n",
    "transformations (rotations and scaling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def experiment_1_func(net, _loss_fn, _training_dataset, _testing_dataset, epochs, net_name=\"\", train_attack=None,\n",
    "                      load_checkpoint=False, save_checkpoint=False, show_plots=False, save_plots=False):\n",
    "    \"\"\"\n",
    "    This experiment applies training or adversarial training on the given network. Then it prints the resistant\n",
    "    measurements on both PGD and FGSM attacks.\n",
    "    :param net: the given network. we initialize net parameters.\n",
    "    :param _loss_fn: loss function.\n",
    "    :param _training_dataset: the dataset to train on.\n",
    "    :param _testing_dataset: a separate dataset to measure resistance and accuracy on.\n",
    "    :param epochs: Epochs object that manages the training procedure. see Epochs class in trainer.py for more details.\n",
    "    :param net_name: the network name is used in plotting titles and checkpoints files names.\n",
    "    :param train_attack: in case we want to apply an adversarial training instead of normal training.\n",
    "    :param load_checkpoint: use pre-trained model. To use that verify the existence of one in checkpoints folder.\n",
    "    :param save_checkpoint: save the trained model.\n",
    "    :return: the resistance results + found hps in the hyperparameter searches + trained network.\n",
    "    \"\"\"\n",
    "    if load_checkpoint:\n",
    "        checkpoint_path = os.path.join(experiment_checkpoints_folder, \"{}.pt\".format(net_name))\n",
    "        logger.log_print(\"load network from {}\".format(checkpoint_path))\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        net.load_state_dict(checkpoint[\"trained_net\"])\n",
    "        net_hp = checkpoint[\"net_hp\"]\n",
    "        fgsm_hp = checkpoint[\"fgsm_hp\"]\n",
    "        pgd_hp = checkpoint[\"pgd_hp\"]\n",
    "        resistance_results = checkpoint[\"resistance_results\"]\n",
    "\n",
    "    else:\n",
    "        # apply hyperparameters-search to get a trained network\n",
    "        net_state_dict, net_hp = helper.full_train_of_nn_with_hps(net, _loss_fn, _training_dataset,\n",
    "                                                                  net_training_hps_gen, epochs, device=device,\n",
    "                                                                  train_attack=train_attack)\n",
    "        net.load_state_dict(net_state_dict)\n",
    "        net.eval()  # from now on we only evaluate net.\n",
    "\n",
    "        logger.log_print(\"training selected hyperparams: {}\".format(str(net_hp)))\n",
    "\n",
    "        # attack selected net using FGSM:\n",
    "        fgsm_hp, fgsm_score = helper.full_attack_of_trained_nn_with_hps(net, _loss_fn, _training_dataset,\n",
    "                                                                        fgsm_attack_hps_gen, net_hp, attacks.FGSM,\n",
    "                                                                        device=device, plot_results=False,\n",
    "                                                                        save_figs=False, figs_path=plots_folder)\n",
    "        logger.log_print(\"FGSM attack selected hyperparams: {}\".format(str(fgsm_hp)))\n",
    "\n",
    "        # attack selected net using PGD:\n",
    "        pgd_hp, pgd_score = helper.full_attack_of_trained_nn_with_hps(net, _loss_fn, _training_dataset,\n",
    "                                                                      pgd_attack_hps_gen, net_hp, attacks.PGD,\n",
    "                                                                      device=device, plot_results=False,\n",
    "                                                                      save_figs=False,\n",
    "                                                                      figs_path=plots_folder)\n",
    "        logger.log_print(\"PGD attack selected hyperparams: {}\".format(str(pgd_hp)))\n",
    "\n",
    "        # measure attacks on test (holdout)\n",
    "        resistance_results = helper.measure_resistance_on_test(net, _loss_fn, _testing_dataset,\n",
    "                                                               to_attacks=[(attacks.FGSM, fgsm_hp),\n",
    "                                                                           (attacks.PGD, pgd_hp)],\n",
    "                                                               device=device,\n",
    "                                                               plot_results=show_plots,\n",
    "                                                               save_figs=save_plots,\n",
    "                                                               figs_path=plots_folder,\n",
    "                                                               plots_title=net_name)\n",
    "\n",
    "    # unpack resistance_results\n",
    "    test_acc = resistance_results[\"test_acc\"]  # the accuracy without applying any attack\n",
    "    fgsm_res = resistance_results[\"%fgsm\"]\n",
    "    pgd_res = resistance_results[\"%pgd\"]\n",
    "\n",
    "    # print scores:\n",
    "    logger.log_print(\"TEST SCORES of {}:\".format(net_name))\n",
    "    logger.log_print(\"accuracy on test:            {}\".format(test_acc))\n",
    "    logger.log_print(\"%FGSM successful attacks:    {}\".format(fgsm_res))\n",
    "    logger.log_print(\"%PGD successful attacks:     {}\".format(pgd_res))\n",
    "\n",
    "    # save checkpoint\n",
    "    res_dict = {\n",
    "        \"trained_net\": net,\n",
    "        \"net_hp\": net_hp,\n",
    "        \"fgsm_hp\": fgsm_hp,\n",
    "        \"pgd_hp\": pgd_hp,\n",
    "        \"resistance_results\": resistance_results\n",
    "    }\n",
    "\n",
    "    if save_checkpoint and not load_checkpoint:\n",
    "        to_save_res_dict = res_dict\n",
    "        to_save_res_dict[\"trained_net\"] = net.state_dict()\n",
    "        checkpoint_path = os.path.join(experiment_checkpoints_folder, \"{}.pt\".format(net_name))\n",
    "        logger.log_print(\"save network to {}\".format(checkpoint_path))\n",
    "        torch.save(to_save_res_dict, checkpoint_path)\n",
    "\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment1(net_arch, _loss_fn, _training_dataset, _testing_dataset, epochs):\n",
    "    net_name = net_arch.name\n",
    "\n",
    "    logger.new_section() # some new lines\n",
    "    logger.log_print(\"Experiment 1 on {}\".format(net_name))\n",
    "    # print network summary to log\n",
    "    original_net = net_arch().to(device)\n",
    "    logger.log_print(\"Network architecture\")\n",
    "    logger.log_print(str(original_net))\n",
    "    # apply experimet 1\n",
    "    exp1_res_dict = experiment_1_func(original_net, _loss_fn, _training_dataset, _testing_dataset, epochs, \n",
    "                                      net_name=net_name,\n",
    "                                      save_checkpoint=configs.save_checkpoints,\n",
    "                                      load_checkpoint=configs.load_checkpoints,\n",
    "                                      show_plots=configs.show_attacks_plots,\n",
    "                                      save_plots=configs.save_attacks_plots)\n",
    "    return exp1_res_dict\n",
    "\n",
    "\n",
    "net_arch = models.MNISTNet\n",
    "exp1_res_dict = run_experiment1(net_arch, _loss_fn, _training_dataset, _testing_dataset, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Comparing defensing using FGSM versus using PGD\n",
    "\n",
    "In this experiment we will use adversarial training (the paper procedure) in order to make the network from experiment 1 resistant to FGSM and PGD attacks separately. Denote the network that trained in adversarial training using FGSM as Net_1 and the network trained with PGD as Net_2. Then we test Net_1,Net_2 robustness as we did in experiment 1 and show the following:\n",
    "\n",
    "1. Net_1 is resistant to FGSM attack but not to PGD attack. What means resistant against FGSM doesn't yields resistance against PGD.\n",
    "\n",
    "2. Net_2 is resistance to both FGSM and PGD attacks. This is a motivation to experiment 3 that shows PGD is a universal attack. (i.e. that resistance against PGD yields resistance to any other first order attack).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment_2_func(exp1_res_dict, net_arch, _loss_fn, _training_dataset, _testing_dataset, adversarial_epochs,\n",
    "                      net_name=\"\", load_checkpoint=False, save_checkpoint=False, show_plots=False, save_plots=False):\n",
    "    # fgsm_hp = exp1_res_dict[\"fgsm_hp\"]\n",
    "    # pgd_hp = exp1_res_dict[\"pgd_hp\"]\n",
    "    fgsm_hp = {\"epsilon\": 0.08}\n",
    "    pgd_hp = {\"epsilon\": 0.15}\n",
    "\n",
    "    # adversarial_epochs.restart()\n",
    "    # fgsm_robust_net = net_arch().to(device)\n",
    "    # fgsm_attack = attacks.FGSM(fgsm_robust_net, _loss_fn, fgsm_hp)\n",
    "    # experiment_1_func(fgsm_robust_net, _loss_fn, _training_dataset, _testing_dataset, adversarial_epochs,\n",
    "    #                   net_name=\"{} with FGSM adversarial training\".format(net_name), train_attack=fgsm_attack,\n",
    "    #                   load_checkpoint=load_checkpoint, save_checkpoint=save_checkpoint, show_plots=show_plots,\n",
    "    #                   save_plots=save_plots)\n",
    "\n",
    "    adversarial_epochs.restart()\n",
    "    pgd_robust_net = net_arch().to(device)\n",
    "    pgd_attack = attacks.PGD(pgd_robust_net, _loss_fn, pgd_hp)\n",
    "    experiment_1_func(pgd_robust_net, _loss_fn, _training_dataset, _testing_dataset, adversarial_epochs,\n",
    "                      net_name=\"{} with PGD adversarial training\".format(net_name), train_attack=pgd_attack,\n",
    "                      load_checkpoint=load_checkpoint, save_checkpoint=save_checkpoint, show_plots=show_plots,\n",
    "                      save_plots=save_plots)\n",
    "    return pgd_robust_net\n",
    "\n",
    "def run_experiment2(exp1_res_dict, net_arch, _loss_fn, _training_dataset, _testing_dataset, adv_epochs):\n",
    "    net_name = net_arch.name\n",
    "\n",
    "    logger.new_section() # some new lines\n",
    "    logger.log_print(\"Experiment 2 on {}\".format(net_name))\n",
    "    experiment_2_func(exp1_res_dict, net_arch, _loss_fn, _training_dataset, _testing_dataset, \n",
    "                  adv_epochs, net_name=net_name,\n",
    "                  save_checkpoint=configs.save_checkpoints,\n",
    "                  load_checkpoint=configs.load_checkpoints,\n",
    "                  show_plots=configs.show_attacks_plots,\n",
    "                  save_plots=configs.save_attacks_plots)\n",
    "\n",
    "pgd_robust_net = run_experiment2(exp1_res_dict, net_arch, _loss_fn, _training_dataset, _testing_dataset, adv_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3:\n",
    "Applying 1+2 on STN instead CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = models.STN_MNISTNet\n",
    "params = [net_arch, _loss_fn, _training_dataset, _testing_dataset]\n",
    "run_experiment2(run_experiment1(*params, epochs), *params, adv_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Capacity and Adversarial Robustness\n",
    "In this experiment we will examine the following statements:\n",
    "\n",
    "1. Capacity alone helps: High capacity models are more robust to adversarial attacks then low capacity models.\n",
    "2. Weak models may fail to learn non-trivial classifiers: We show that we can't build (using the paper method) a robust model\n",
    "   when the model is with low capacity. Specifically we will show that after training with the paper method to build a robust\n",
    "   model we get an extremely underfitted model.\n",
    "3. The value of the saddle point problem decreases as we increase the capacity\n",
    "4. More capacity and stronger adversaries decrease transferability: we take transferred adversarial inputs and show that their\n",
    "   gradients correlation with the source becomes less significant. More details on that experiment can be found in the project file.\n",
    "\n",
    "\n",
    "\n",
    "Technical Details:\n",
    "To create the increased capacity networks we use create_conv_nn from models.py. A description on the parameters is in\n",
    "ConvNN class. In short, channels_lst specifies the number of channels at each layer and extras_blocks_components\n",
    "specifies the components on each block of the network (e.g. dropout, maxpool). #FC_Layers is the number of layers that\n",
    "follows the convolutional layers. There are limitations on some of the parameters - 2 <= len(channels_lst) <= 5\n",
    "and #FC_Layers > 0. CNN_out_channels for applying 1x1 conv layer with CNN_out_channels output channels - None for\n",
    "ignoring this feature. in_wh is width and height of the pictures. out_size is the number of classes. For more details\n",
    "see ConvNN class description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inc_capacity_nets = []\n",
    "base_net_params = {\n",
    "    \"extras_blocks_components\": [],  # [\"dropout\"],\n",
    "    # \"p_dropout\": 0.1,\n",
    "    \"activation\": torch.nn.LeakyReLU,\n",
    "    \"out_size\": 10,\n",
    "    \"in_wh\": 28,\n",
    "    \"CNN_out_channels\": None  # apply 1x1 conv layer to achieve that - to control mem. None to not use.\n",
    "}\n",
    "for i in range(1, 9):\n",
    "    base_net_params[\"channels_lst\"] = [3, 10 * i, 20 * i]\n",
    "    base_net_params[\"#FC_Layers\"] = 1 + i // 2\n",
    "    base_net_params[\"CNN_out_channels\"] = i * 5\n",
    "    cap_net = models.create_conv_nn(base_net_params)\n",
    "    inc_capacity_nets.append(cap_net)\n",
    "for i, net in enumerate(inc_capacity_nets):\n",
    "    net = net.to(device)\n",
    "    epochs.restart()\n",
    "    experiment_1_func(net, _loss_fn, _training_dataset, _testing_dataset, epochs,\n",
    "                        net_name=\"capacity_{}\".format(i))\n",
    "\n",
    "# visualize and stufff........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5: Universality of PGD attack\n",
    "In this experiment we will attack Net_2 from experiment 2 using a various of adversarial attacks with different parameters. We want to show that Net_2 is resistance to all of them. This is an evidence that we can practically use a specific PGD (say with 40 steps and specified epsilon) to defend through stronger attacks.\n",
    "\n",
    "Net_2 is trained with adversarial training with PGD that chosen with #steps=40. We test how good Net_2 defends against increasing #steps and \\epsilon (allowing more options). We examine only CNN networks (performed better than STN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attacks_lst = [\n",
    "    (attacks.FGSM, {\"epsilon\": 0.001}),\n",
    "    (attacks.FGSM, {\"epsilon\": 0.005}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.4, \"steps\": 60, \"alpha\": 0.001}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.2, \"steps\": 20, \"alpha\": 0.005}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.3, \"steps\": 40, \"alpha\": 0.005}),\n",
    "    (attacks.PGD, {\"epsilon\": 0.2, \"steps\": 40, \"alpha\": 0.01}),\n",
    "    (attacks.MomentumFGSM, {\"epsilon\": 0.2, \"steps\": 40, \"alpha\": 0.01, \"momentum\":0.9}),\n",
    "    (attacks.MomentumFGSM, {\"epsilon\": 0.4, \"steps\": 30, \"alpha\": 0.001, \"momentum\":0.95}),\n",
    "]\n",
    "pgd_resistance_results = helper.measure_resistance_on_test(pgd_robust_net, _loss_fn, _testing_dataset, attacks_lst,\n",
    "                                                           plots_title=\"robust net built using PGD\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}